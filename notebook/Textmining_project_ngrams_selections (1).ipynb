{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy3UWVr3xY47",
        "outputId": "8c738c74-3b81-4db5-8527-1d3d8f39830d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import os\n",
        "import gensim.downloader as api\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import words\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.manifold import TSNE\n",
        "import gensim.downloader as api\n",
        "import re\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models import Word2Vec\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# will be used to analyse all three dataframes \n",
        "word_vectors = api.load('glove-wiki-gigaword-300')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yytBiCHdJrXp",
        "outputId": "231a9552-5c67-4a84-d7c6-d00d8c95a8d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZSF7SlhExcmX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "ccca045d-f96a-4a45-f490-32ac73b1473e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0      Id                                            Comment  \\\n",
              "0               0   0x840  A few things. You might have negative- frequen...   \n",
              "1               1   0xbf0  Is it so hard to believe that there exist part...   \n",
              "2               2  0x1dfc                                     There are bees   \n",
              "3               3   0xc7e  I'm a medication technician. And that's alot o...   \n",
              "4               4   0xbba                     Cesium is such a pretty metal.   \n",
              "...           ...     ...                                                ...   \n",
              "10276        1581  0x22bf  I’m not really denying your intent. I’m a) dou...   \n",
              "10277        1582  0x1f4a  i really empathize with your compassion for bu...   \n",
              "10278        1583  0x27b7  If you want to keep it for more than 2 weeks, ...   \n",
              "10279        1584  0x2066  Same here. I’m in nursing school so I only hav...   \n",
              "10280        1585   0x6d6  The video basically says read a pop-sci book a...   \n",
              "\n",
              "           Topic                                   cleaned_Comments  \n",
              "0        Biology  thing you might negative frequency dependent s...  \n",
              "1        Physics  hard believe exist particular detect anything ...  \n",
              "2        Biology                                          there bee  \n",
              "3        Biology  medication technician and alot drug liver you ...  \n",
              "4      Chemistry                                cesium pretty metal  \n",
              "...          ...                                                ...  \n",
              "10276  Chemistry  really denying intent doubting third comment i...  \n",
              "10277    Biology  really empathize compassion bug entomology rea...  \n",
              "10278  Chemistry  want keep week would something like you also w...  \n",
              "10279    Biology  same nursing school basic understanding thing ...  \n",
              "10280    Physics  the video basically say read book want quantum...  \n",
              "\n",
              "[10281 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-746ebe76-a344-44de-b295-dc5001892e1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Id</th>\n",
              "      <th>Comment</th>\n",
              "      <th>Topic</th>\n",
              "      <th>cleaned_Comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0x840</td>\n",
              "      <td>A few things. You might have negative- frequen...</td>\n",
              "      <td>Biology</td>\n",
              "      <td>thing you might negative frequency dependent s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0xbf0</td>\n",
              "      <td>Is it so hard to believe that there exist part...</td>\n",
              "      <td>Physics</td>\n",
              "      <td>hard believe exist particular detect anything ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0x1dfc</td>\n",
              "      <td>There are bees</td>\n",
              "      <td>Biology</td>\n",
              "      <td>there bee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0xc7e</td>\n",
              "      <td>I'm a medication technician. And that's alot o...</td>\n",
              "      <td>Biology</td>\n",
              "      <td>medication technician and alot drug liver you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0xbba</td>\n",
              "      <td>Cesium is such a pretty metal.</td>\n",
              "      <td>Chemistry</td>\n",
              "      <td>cesium pretty metal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10276</th>\n",
              "      <td>1581</td>\n",
              "      <td>0x22bf</td>\n",
              "      <td>I’m not really denying your intent. I’m a) dou...</td>\n",
              "      <td>Chemistry</td>\n",
              "      <td>really denying intent doubting third comment i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10277</th>\n",
              "      <td>1582</td>\n",
              "      <td>0x1f4a</td>\n",
              "      <td>i really empathize with your compassion for bu...</td>\n",
              "      <td>Biology</td>\n",
              "      <td>really empathize compassion bug entomology rea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10278</th>\n",
              "      <td>1583</td>\n",
              "      <td>0x27b7</td>\n",
              "      <td>If you want to keep it for more than 2 weeks, ...</td>\n",
              "      <td>Chemistry</td>\n",
              "      <td>want keep week would something like you also w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10279</th>\n",
              "      <td>1584</td>\n",
              "      <td>0x2066</td>\n",
              "      <td>Same here. I’m in nursing school so I only hav...</td>\n",
              "      <td>Biology</td>\n",
              "      <td>same nursing school basic understanding thing ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10280</th>\n",
              "      <td>1585</td>\n",
              "      <td>0x6d6</td>\n",
              "      <td>The video basically says read a pop-sci book a...</td>\n",
              "      <td>Physics</td>\n",
              "      <td>the video basically say read book want quantum...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10281 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-746ebe76-a344-44de-b295-dc5001892e1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-746ebe76-a344-44de-b295-dc5001892e1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-746ebe76-a344-44de-b295-dc5001892e1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "blogdf = pd.read_csv('/content/drive/MyDrive/text_mining_project/naturalscience/attempt2.csv')\n",
        "\n",
        "words = pd.read_csv('/content/drive/MyDrive/text_mining_project/naturalscience/facktermer_naturvetenskap.csv') \n",
        "\n",
        "words_biology = words[words['theme'] == 'Biology']['words'].unique().tolist()\n",
        "words_physics = words[words['theme'] == 'Physics']['words'].unique().tolist()\n",
        "words_chemistry = words[words['theme'] == 'Chemistry']['words'].unique().tolist()\n",
        "\n",
        "blogdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Selecting_threegrams: \n",
        "  def __init__(self, blogposts): \n",
        "    # här sparar jag alla n-grams \n",
        "    self.threegram_dict={}  \n",
        "    self.blogposts = blogposts \n",
        "\n",
        "  def store_three_grams(self):  \n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    throwawaylist = {}\n",
        "    self.three_gram_dict = { } \n",
        "\n",
        "\n",
        "    def ngram(inputwordlist): \n",
        "      ngramlist = [(wordlist[l],wordlist[l+1], wordlist[l+2])   for l in range(LW-2)]  \n",
        "\n",
        "      uniquelist = [ ]\n",
        "      for ngram in ngramlist:\n",
        "        if ngram not in uniquelist:\n",
        "          uniquelist.append(ngram) \n",
        "\n",
        "      for ngram in uniquelist: \n",
        "        if ngram not in self.threegram_dict:\n",
        "          self.threegram_dict[ngram] = 1\n",
        "        else: \n",
        "          self.threegram_dict[ngram] += 1\n",
        "\n",
        "    for blogs in self.blogposts: \n",
        "      try:\n",
        "        wordlist = blogs.split() \n",
        "        LW = len(wordlist)\n",
        "        if LW > 4: \n",
        "          ngram(wordlist)\n",
        "      except: \n",
        "        throwawaylist.append(blogs)\n",
        "    trigrams = [ ]\n",
        "    for k, v in self.threegram_dict.items(): \n",
        "      if v > 3: \n",
        "        phrase = ' '.join(k)\n",
        "        trigrams.append(phrase)\n",
        "    return trigrams\n",
        "\n",
        "\n",
        "\n",
        "  def popular_two_grams(self, number, wordlist): \n",
        "      newdict = { }\n",
        "      for k, v in self.threegram_dict.items():  \n",
        "        word1 = k[0]\n",
        "        word2 = k[1] \n",
        "        word3 = k[2] \n",
        "        if word1 in wordlist or word2 in wordlist or word3 in wordlist:\n",
        "          if v > number: \n",
        "            newdict[' '.join(k)] = v\n",
        "\n",
        "      sorted_list = sorted(newdict.items(), key=lambda x: x[1], reverse=True)  \n",
        "\n",
        "      self.sorted_list = sorted_list  \n"
      ],
      "metadata": {
        "id": "vbJpn-PGZyfw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blogs = blogdf['Comment'].dropna(how='all')\n",
        "Biology_blogs = blogdf[blogdf['Topic']=='Biology']['cleaned_Comments'].dropna()\n",
        "\n",
        "model1 = Selecting_threegrams(Biology_blogs.tolist() )\n",
        "model1.store_three_grams( )\n",
        "model1.popular_two_grams(2, words_biology )"
      ],
      "metadata": {
        "id": "96Or6Hkrol3q"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blogs = blogdf['Comment'].dropna(how='all')\n",
        "Physics_blogs = blogdf[blogdf['Topic']=='Physics']['cleaned_Comments'].dropna()\n",
        "\n",
        "model1 = Selecting_threegrams(Physics_blogs.tolist() )\n",
        "model1.store_three_grams( )\n",
        "model1.popular_two_grams(2, words_physics ) "
      ],
      "metadata": {
        "id": "pI9YraeqeLas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blogs = blogdf['Comment'].dropna(how='all')\n",
        "Chemistry_blogs = blogdf[blogdf['Topic']=='Chemistry']['Comment'].dropna()\n",
        "\n",
        "model1 = Selecting_threegrams(Chemistry_blogs.tolist() )\n",
        "model1.store_three_grams( )\n",
        "model1.popular_two_grams(1, words_chemistry )"
      ],
      "metadata": {
        "id": "jMVxH8-ieTPp"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Selecting_ngrams: \n",
        "  def __init__(self, blogposts): \n",
        "    # här sparar jag alla n-grams \n",
        "    self.twogram_dict={}  \n",
        "    self.blogposts = blogposts \n",
        "\n",
        "  def store_two_grams(self):  \n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    self.twogramdict = { }\n",
        "    newngramdict = {} \n",
        "    throwawaylist = []\n",
        "\n",
        "    def ngrams(wordlist): \n",
        "      ngramlist = [(wordlist[l],wordlist[l+1])   for l in range(LW-1)]  \n",
        "\n",
        "      for ngram in ngramlist: \n",
        "        current_ngram = ' '.join(ngram)\n",
        "        doc = nlp(current_ngram) \n",
        "        pos = [ ]\n",
        "        for token in doc: \n",
        "          # to check the part-of-speech tags\n",
        "          pos.append(token.pos_)  \n",
        "        if pos[0] == 'NOUN' and pos[1] == 'NOUN':\n",
        "          if ngram not in self.twogram_dict:\n",
        "            self.twogram_dict[ngram] = 1\n",
        "          else: \n",
        "            self.twogram_dict[ngram] += 1\n",
        "\n",
        "    for blogs in self.blogposts: \n",
        "      try:\n",
        "        wordlist = blogs.split() \n",
        "        LW = len(wordlist)\n",
        "        if LW > 2: \n",
        "          ngrams(wordlist)\n",
        "      except: \n",
        "        throwawaylist.append(blogs)\n",
        "\n",
        "\n",
        "\n",
        "  def popular_two_grams(self, number, wordlist): \n",
        "      newdict = { }\n",
        "      self.included_keywords = []\n",
        "      for k, v in self.twogram_dict.items():  \n",
        "        word1 = k[0]\n",
        "        word2 = k[1] \n",
        "        if word1 in wordlist or word2 in wordlist:\n",
        "          if word1 in wordlist: \n",
        "            self.included_keywords.append(word1)\n",
        "          if word2 in wordlist:\n",
        "            self.included_keywords.append(word1)\n",
        "          if v > number: \n",
        "            newdict[' '.join(k)] = v\n",
        "\n",
        "      sorted_list = sorted(newdict.items(), key=lambda x: x[1], reverse=True)  \n",
        "\n",
        "      self.sorted_list = sorted_list  \n",
        "\n",
        "      selectedlist = [ ]\n",
        "\n",
        "      # to create a list over selected list: \n",
        "      for elem in sorted_list: \n",
        "        selectedlist.append(elem[0])\n",
        "\n",
        "      return selectedlist\n",
        "\n",
        "  def create_new_dataframe(self, selected_ngramlist): \n",
        "    # to create a new dataframe to store the twograms \n",
        "    twogram_list = [ ]\n",
        "    cleaned_text = [ ] \n",
        "    throwawaylist = [ ]  \n",
        "\n",
        "    def process_blogs(inputlist): \n",
        "      ngramlist = [(wordlist[l],wordlist[l+1])   for l in range(LW-1)]  \n",
        "      uniquelist = []\n",
        "      for ngram in ngramlist:\n",
        "        if ngram not in uniquelist:\n",
        "          uniquelist.append(ngram)\n",
        "\n",
        "      for ngram in uniquelist: \n",
        "        phrase = ' '.join(ngram) \n",
        "        if phrase in selected_ngramlist: \n",
        "          twogram_list.append(phrase) \n",
        "          cleaned_text.append(' '.join(inputlist) )\n",
        "\n",
        "    for blogs in self.blogposts: \n",
        "      try:\n",
        "        wordlist = blogs.split() \n",
        "        LW = len(wordlist)\n",
        "        if LW > 2: \n",
        "          process_blogs(wordlist)\n",
        "      except: \n",
        "        throwawaylist.append(blogs)  \n",
        "\n",
        "    twogram_df = pd.DataFrame(list(zip(twogram_list, cleaned_text)),\n",
        "               columns =['ngrams', 'Cleaned_text'])\n",
        "\n",
        "    return twogram_df\n",
        "    "
      ],
      "metadata": {
        "id": "cfgczGm1pHKm"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blogs = blogdf['cleaned_Comments'].dropna(how='all')\n",
        "physics_blogs = blogdf[blogdf['Topic']=='Chemistry']['cleaned_Comments'].tolist()\n",
        "\n",
        "model1 = Selecting_ngrams(physics_blogs) \n",
        "\n",
        "model1.store_two_grams( )\n",
        "listofwords = model1.popular_two_grams( number = 2, wordlist = words_chemistry)\n",
        "#twogram_df = model1.create_new_dataframe(listofwords3)\n",
        "dikt_trigram = model1.sorted_list\n",
        "newtrigramlist = [ ]\n",
        "for elem in dikt_trigram: \n",
        "    newtrigramlist.append(elem[0])"
      ],
      "metadata": {
        "id": "W9Ok2CoVZnuH"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twogram_df = model1.create_new_dataframe(listofwords4)\n",
        "twogram_df\n",
        "twogram_df.to_csv('/content/drive/MyDrive/text_mining_project/naturalscience/twograms_chemistry.csv') "
      ],
      "metadata": {
        "id": "L4FC0SxHxcWj"
      },
      "execution_count": 58,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Textmining_project_ngrams_selections.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}